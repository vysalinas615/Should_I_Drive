{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srPvL58L_QMG",
        "outputId": "a91f9506-ee6d-4f79-fdc2-0d754f8baabd"
      },
      "id": "srPvL58L_QMG",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/drive/MyDrive/allDatanew.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om8S9GkgAYFv",
        "outputId": "0e5406bc-626c-471d-929f-ffec146f214d"
      },
      "id": "Om8S9GkgAYFv",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/allDatanew.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load necessary imports"
      ],
      "metadata": {
        "id": "SwDz8iZY7bnl"
      },
      "id": "SwDz8iZY7bnl"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
        "\n",
        "from torch.utils.data import Subset\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms, utils\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "cuda_enabled = torch.cuda.is_available()\n",
        "# # Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# CUDA_VISIBLE_DEVICES=0,1,2,3\n",
        "cudnn.benchmark = True\n",
        "\n",
        "from skimage import io, transform\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "from __future__ import print_function, division\n",
        "import datetime\n",
        "import sys\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from ast import literal_eval\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "metadata": {
        "id": "NTjXNkp6CmTf"
      },
      "id": "NTjXNkp6CmTf",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "C1DRIoo5C-AC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b914c01-c576-48ce-971c-241ff58d9f7d"
      },
      "id": "C1DRIoo5C-AC",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KiYlVAV_fwA",
        "outputId": "95f21314-2ee9-441b-db8b-b3471f7968c3"
      },
      "id": "_KiYlVAV_fwA",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon May 16 19:50:02 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8    11W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c332384-b38b-4c5f-b33d-20b1339ea1c1",
      "metadata": {
        "id": "7c332384-b38b-4c5f-b33d-20b1339ea1c1"
      },
      "source": [
        "\n",
        "#### Bidirectional Recurrent Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f03db30d-3bf9-4d6a-860d-29802567c6aa",
      "metadata": {
        "id": "f03db30d-3bf9-4d6a-860d-29802567c6aa"
      },
      "outputs": [],
      "source": [
        "# Bidirectional recurrent neural network (many-to-one)\n",
        "class BiRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(BiRNN, self).__init__()\n",
        "        self.is_training = False\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.num_classes = num_classes\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Dropout(p=0.5, inplace=False)\n",
        "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
        "        self.linear = nn.Linear(self.hidden_size*2, self.num_classes)\n",
        "        if cuda_enabled:\n",
        "            self.lstm = self.lstm.cuda()\n",
        "            self.fc = self.fc.cuda()\n",
        "            self.linear = self.linear.cuda()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Set initial states\n",
        "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
        "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
        "        if cuda_enabled:\n",
        "            h0 = h0.cuda()  # 2 for bidirection\n",
        "            c0 = c0.cuda()\n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
        "        \n",
        "        # Decode hidden state of last time step\n",
        "        if self.is_training:\n",
        "            out = self.fc(out[:, -1, :])\n",
        "        else:\n",
        "            out = out[:, -1, :]\n",
        "        # out = F.log_softmax(self.linear(out), dim=1)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d50dce79-b872-4d4e-a08b-b92d47cbb858",
      "metadata": {
        "id": "d50dce79-b872-4d4e-a08b-b92d47cbb858"
      },
      "source": [
        "Dataset class\n",
        "-------------\n",
        "\n",
        "``torch.utils.data.Dataset`` is an abstract class representing a\n",
        "dataset.\n",
        "Your custom dataset should inherit ``Dataset`` and override the following\n",
        "methods:\n",
        "\n",
        "-  ``__len__`` so that ``len(dataset)`` returns the size of the dataset.\n",
        "-  ``__getitem__`` to support the indexing such that ``dataset[i]`` can\n",
        "   be used to get $i$\\ th sample.\n",
        "\n",
        "Let's create a dataset class for our face landmarks dataset. We will\n",
        "read the csv in ``__init__`` but leave the reading of images to\n",
        "``__getitem__``. This is memory efficient because all the images are not\n",
        "stored in the memory at once but read as required.\n",
        "\n",
        "Sample of our dataset will be a dict\n",
        "``{'image': image, 'landmarks': landmarks}``. Our dataset will take an\n",
        "optional argument ``transform`` so that any required processing can be\n",
        "applied on the sample. We will see the usefulness of ``transform`` in the\n",
        "next section.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eye Dataset"
      ],
      "metadata": {
        "id": "XlxlY-wp548R"
      },
      "id": "XlxlY-wp548R"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "686bdda5-302e-4028-ad3a-bd522756a123",
      "metadata": {
        "jupyter": {
          "outputs_hidden": false
        },
        "id": "686bdda5-302e-4028-ad3a-bd522756a123"
      },
      "outputs": [],
      "source": [
        "class EyeLandmarksDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, transform=None):#root_dir = img_dir\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.landmarks_frame = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.landmarks_frame)#same as image label\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, 0])\n",
        "        name = self.landmarks_frame.iloc[idx, 0]\n",
        "        labels = np.zeros(8)\n",
        "        for i in range(8):\n",
        "            labels[i]=name\n",
        "        labels = torch.Tensor(labels).long()\n",
        "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
        "        marks = []\n",
        "        for mark in range(len(landmarks)):\n",
        "            arr = literal_eval(landmarks[mark])[0]\n",
        "            arr1 = []\n",
        "            for i in range(len(arr)):\n",
        "                for j in range(len(arr[i])):\n",
        "                    arr1.append(arr[i][j])\n",
        "            marks.append(np.array(arr1))                            \n",
        "        marks = torch.Tensor(marks)\n",
        "        \n",
        "        sample = {'label': labels, 'marks': marks}\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return sample"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Body Dataset"
      ],
      "metadata": {
        "id": "AY9q8GT257RQ"
      },
      "id": "AY9q8GT257RQ"
    },
    {
      "cell_type": "code",
      "source": [
        "class BodyLandmarksDataset(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, csv_file, transform=None):#root_dir = img_dir\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.landmarks_frame = pd.read_csv(csv_file)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.landmarks_frame)#same as image label\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        # name = os.path.join(self.root_dir, self.landmarks_frame.iloc[idx, 0])\n",
        "        name = self.landmarks_frame.iloc[idx, 0]\n",
        "        labels = np.zeros(36)\n",
        "        for i in range(36):\n",
        "            labels[i]=name\n",
        "        labels = torch.Tensor(labels).long()\n",
        "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
        "        marks = []\n",
        "        for mark in range(len(landmarks)):\n",
        "            arr=literal_eval(landmarks[mark])\n",
        "            arr1=[]\n",
        "            for i in range(len(arr)):\n",
        "                arr1.append(float(arr[i]))\n",
        "                           \n",
        "            arr1 = np.array(arr1)\n",
        "            marks.append(arr1)\n",
        "                 \n",
        "        marks = torch.Tensor(marks)\n",
        "        \n",
        "        sample = {'label': labels, 'marks': marks}\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "        return sample"
      ],
      "metadata": {
        "id": "h7ncUeoRY-hU"
      },
      "id": "h7ncUeoRY-hU",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Eye Dataset"
      ],
      "metadata": {
        "id": "56sL0Hp26BG4"
      },
      "id": "56sL0Hp26BG4"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "7a5fa1a8-4f8d-4408-90f6-ea3f67ea78ed",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a5fa1a8-4f8d-4408-90f6-ea3f67ea78ed",
        "outputId": "9aa9c413-ced9-4bec-8d47-93c08967a39b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(229, torch.Size([8]), torch.Size([511, 8]))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "eyedataset = EyeLandmarksDataset(csv_file='/content/drive/MyDrive/allDatanew.csv')\n",
        "eyedataset.__len__(), eyedataset.__getitem__(0)['label'].shape, eyedataset.__getitem__(0)['marks'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Body Dataset"
      ],
      "metadata": {
        "id": "K0LQ9nai6EJe"
      },
      "id": "K0LQ9nai6EJe"
    },
    {
      "cell_type": "code",
      "source": [
        "bodydataset = BodyLandmarksDataset(csv_file='/content/drive/MyDrive/noBlanksnew.csv')\n",
        "bodydataset.__len__(), bodydataset.__getitem__(0)['label'].shape, bodydataset.__getitem__(0)['marks'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHUl6bP6ZHKc",
        "outputId": "9c924c6a-4144-4c3f-e2c8-e2c10c927238"
      },
      "id": "YHUl6bP6ZHKc",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(217, torch.Size([36]), torch.Size([511, 36]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bodydataset.__getitem__(100)['label'], bodydataset.__getitem__(100)['marks']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6X-EI7AsZjaR",
        "outputId": "68152c4c-40b3-4154-a8e6-4660620cbcd5"
      },
      "id": "6X-EI7AsZjaR",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
              " tensor([[834., 156.,  -1.,  ..., 156.,  -1.,  -1.],\n",
              "         [806., 140.,  -1.,  ..., 156.,  -1.,  -1.],\n",
              "         [806., 140.,  -1.,  ..., 156.,  -1.,  -1.],\n",
              "         ...,\n",
              "         [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.],\n",
              "         [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.],\n",
              "         [ -1.,  -1.,  -1.,  ...,  -1.,  -1.,  -1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5314b415-739b-46b9-934e-e1d3817ef059",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5314b415-739b-46b9-934e-e1d3817ef059",
        "outputId": "d76552b0-5561-42f7-c0b4-49a02e0570dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 42.,  56.,  52.,  52., 123.,  69.,  39.,  39.],\n",
              "         [124.,  69.,  38.,  38.,  86., 144.,  57.,  57.],\n",
              "         [122.,  65.,  43.,  43.,  81., 141.,  63.,  63.],\n",
              "         [ 39.,  56.,  55.,  55., 122.,  62.,  49.,  49.],\n",
              "         [ 34.,  57.,  54.,  54., 117.,  60.,  51.,  51.]]),\n",
              " tensor([1, 1, 1, 1, 1, 1, 1, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "eyedataset.__getitem__(228)['marks'][:5], eyedataset.__getitem__(228)['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Divide Dataset for Training and Testing\n"
      ],
      "metadata": {
        "id": "eezp8J_v6QPC"
      },
      "id": "eezp8J_v6QPC"
    },
    {
      "cell_type": "code",
      "source": [
        "def train_total_dataset(dataset, total_split=0.30): #Training set be 70% of the dataset\n",
        "    train_idx, total_idx = train_test_split(list(range(len(dataset))), test_size=total_split)\n",
        "    datasets = {}\n",
        "    datasets['train'] = Subset(dataset, train_idx)\n",
        "    datasets['total_split'] = Subset(dataset, total_idx)\n",
        "    return datasets\n",
        "\n",
        "# hyperparams for the network\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "PcgLPqpNeMGy"
      },
      "id": "PcgLPqpNeMGy",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Eye NN Loders"
      ],
      "metadata": {
        "id": "5ttIV8wx6YNo"
      },
      "id": "5ttIV8wx6YNo"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "699e8fad-b758-4b3e-a825-631afb2c51c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "699e8fad-b758-4b3e-a825-631afb2c51c7",
        "outputId": "e585df4e-b725-42ab-f826-85ee44dc8fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Eye NN dataset -------------------------------------\n",
            "229 <__main__.EyeLandmarksDataset object at 0x7f546cc310d0>\n",
            "160 <torch.utils.data.dataset.Subset object at 0x7f546ca31dd0>\n",
            "69 <torch.utils.data.dataset.Subset object at 0x7f546ca31550>\n",
            "Starting Eye NN loader -------------------------------------\n",
            "3 <torch.utils.data.dataloader.DataLoader object at 0x7f546ca31f10>\n",
            "2 <torch.utils.data.dataloader.DataLoader object at 0x7f546ca31f90>\n",
            "Finish  -------------------------------------\n"
          ]
        }
      ],
      "source": [
        "print('Starting Eye NN dataset -------------------------------------')\n",
        "eye_datasets = train_total_dataset(eyedataset)\n",
        "eye_train = eye_datasets['train']\n",
        "eye_test = eye_datasets['total_split']\n",
        "# The original dataset is available in the Subset class\n",
        "print(len(eye_datasets['train'].dataset), eye_datasets['train'].dataset)\n",
        "print(len(eye_train), eye_train)\n",
        "print(len(eye_test), eye_test)\n",
        "\n",
        "print('Starting Eye NN loader -------------------------------------')\n",
        "eye_train_loader = DataLoader(dataset=eye_train, batch_size=batch_size, shuffle=True)\n",
        "eye_test_loader = DataLoader(dataset=eye_test, batch_size=batch_size, shuffle=False)\n",
        "print(len(eye_train_loader), eye_train_loader)\n",
        "print(len(eye_test_loader), eye_test_loader)\n",
        "print('Finish  -------------------------------------')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Body NN Loders"
      ],
      "metadata": {
        "id": "YhYaTVu-6chE"
      },
      "id": "YhYaTVu-6chE"
    },
    {
      "cell_type": "code",
      "source": [
        "print('Starting Body NN dataset -------------------------------------')\n",
        "body_datasets = train_total_dataset(bodydataset)\n",
        "body_train = body_datasets['train']\n",
        "body_test = body_datasets['total_split']\n",
        "# The original dataset is available in the Subset class\n",
        "print(len(body_datasets['train'].dataset), body_datasets['train'].dataset)\n",
        "print(len(body_train), body_train)\n",
        "print(len(body_test), body_test)\n",
        "\n",
        "print('Starting Body NN loader -------------------------------------')\n",
        "body_train_loader = DataLoader(dataset=body_train, batch_size=batch_size, shuffle=True)\n",
        "body_test_loader = DataLoader(dataset=body_test, batch_size=batch_size, shuffle=False)\n",
        "print(len(body_train_loader), body_train_loader)\n",
        "print(len(body_test_loader), body_test_loader)\n",
        "print('Finish  -------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyT9Ax6keUPu",
        "outputId": "8a865e93-c864-4f71-e9a2-ab612c9e020a"
      },
      "id": "OyT9Ax6keUPu",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Body NN dataset -------------------------------------\n",
            "217 <__main__.BodyLandmarksDataset object at 0x7f546dfe5890>\n",
            "151 <torch.utils.data.dataset.Subset object at 0x7f546cf3bed0>\n",
            "66 <torch.utils.data.dataset.Subset object at 0x7f546cf23210>\n",
            "Starting Body NN loader -------------------------------------\n",
            "3 <torch.utils.data.dataloader.DataLoader object at 0x7f546cf230d0>\n",
            "2 <torch.utils.data.dataloader.DataLoader object at 0x7f546cf23a50>\n",
            "Finish  -------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Init parameters"
      ],
      "metadata": {
        "id": "zpWDE5OOfKXL"
      },
      "id": "zpWDE5OOfKXL"
    },
    {
      "cell_type": "code",
      "source": [
        "#Init NN\n",
        "input_size = 1\n",
        "sequence_length = 511\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_classes = 2  # TODO: Determine this from the data\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 300\n",
        "epoch_loss = 5000000000."
      ],
      "metadata": {
        "id": "zKv_XemefHUC"
      },
      "id": "zKv_XemefHUC",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Eye Tracking LSTM"
      ],
      "metadata": {
        "id": "TiRw_HmJe8W8"
      },
      "id": "TiRw_HmJe8W8"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "3341c464-4450-403b-b385-51601065aab7",
      "metadata": {
        "id": "3341c464-4450-403b-b385-51601065aab7"
      },
      "outputs": [],
      "source": [
        "# The network\n",
        "eye_model = BiRNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "eye_model.is_training = True\n",
        "\n",
        "# Loss and optimizer\n",
        "eye_criterion = nn.CrossEntropyLoss()\n",
        "eye_optimizer = torch.optim.Adam(eye_model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Body Tracking LSTM"
      ],
      "metadata": {
        "id": "D7KSSYqce4wY"
      },
      "id": "D7KSSYqce4wY"
    },
    {
      "cell_type": "code",
      "source": [
        "# The network\n",
        "body_model = BiRNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "body_model.is_training = True\n",
        "\n",
        "# Loss and optimizer\n",
        "body_criterion = nn.CrossEntropyLoss()\n",
        "body_optimizer = torch.optim.Adam(body_model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "O59nctKwZdFy"
      },
      "id": "O59nctKwZdFy",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check loaders"
      ],
      "metadata": {
        "id": "TvtmyAs-fhpa"
      },
      "id": "TvtmyAs-fhpa"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "b301f4ac-7bb1-4b23-ba0d-b8d5fd0aea4b",
      "metadata": {
        "id": "b301f4ac-7bb1-4b23-ba0d-b8d5fd0aea4b",
        "outputId": "472775fa-4785-405f-9c12-6cbb59c6b454",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([[154.,  60.,  67.,  67.,  38.,  56.,  66.,  66.],\n",
            "        [ 28.,  54.,  66.,  66., 143.,  62.,  63.,  63.],\n",
            "        [ 36.,  55.,  59.,  59.,  -1.,  -1.,  -1.,  -1.],\n",
            "        [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.],\n",
            "        [ -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.,  -1.]])\n",
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n",
            "tensor([[-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1., -1., -1., -1., -1., -1., -1.],\n",
            "        [-1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1., -1.,\n",
            "         -1., -1., -1., -1., -1., -1., -1., -1.]])\n"
          ]
        }
      ],
      "source": [
        "for i, (sample) in enumerate(eye_train_loader):\n",
        "    labels, marks = sample['label'], sample['marks']\n",
        "    print(labels[0])\n",
        "    print(marks[0][:5])\n",
        "    break\n",
        "\n",
        "for i, (sample) in enumerate(body_train_loader):\n",
        "    labels, marks = sample['label'], sample['marks']\n",
        "    print(labels[0])\n",
        "    print(marks[0][:5])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#just for retesting purposes using only 2 epochs\n",
        "num_epochs = 2\n",
        "#For training purposes we used 300 epochs, we recommend using at least 100 epochs for good training results"
      ],
      "metadata": {
        "id": "gMIZoYbUgDkc"
      },
      "id": "gMIZoYbUgDkc",
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Eye LSTM"
      ],
      "metadata": {
        "id": "IEghVGZdfulf"
      },
      "id": "IEghVGZdfulf"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b0553908-7a75-43b4-95ec-95baefff9602",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0553908-7a75-43b4-95ec-95baefff9602",
        "outputId": "80b2d726-3b95-4317-8856-4d2ae8503ae9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [10/2], Loss: 0.7108\n",
            "Epoch [1/2], Step [20/2], Loss: 0.7989\n",
            "Epoch [1/2], Step [30/2], Loss: 0.6629\n",
            "Epoch [1/2], Step [40/2], Loss: 0.5384\n",
            "Epoch [1/2], Step [50/2], Loss: 0.5374\n",
            "Epoch [1/2], Step [60/2], Loss: 0.6042\n",
            "Epoch [1/2], Step [70/2], Loss: 0.5616\n",
            "Epoch [1/2], Step [80/2], Loss: 0.6309\n",
            "Epoch [1/2], Step [90/2], Loss: 0.6407\n",
            "Epoch [1/2], Step [100/2], Loss: 0.6707\n",
            "Epoch [1/2], Step [110/2], Loss: 0.8269\n",
            "Epoch [1/2], Step [120/2], Loss: 0.7008\n",
            "Epoch [1/2], Step [130/2], Loss: 0.6922\n",
            "Epoch [1/2], Step [140/2], Loss: 0.7707\n",
            "Epoch [1/2], Step [150/2], Loss: 0.5875\n",
            "Epoch [1/2], Step [160/2], Loss: 0.5267\n",
            "Epoch 0; loss = 0.6750\n",
            "0:00:10.204529\n",
            "Epoch [2/2], Step [10/2], Loss: 0.7155\n",
            "Epoch [2/2], Step [20/2], Loss: 0.8112\n",
            "Epoch [2/2], Step [30/2], Loss: 0.6520\n",
            "Epoch [2/2], Step [40/2], Loss: 0.5347\n",
            "Epoch [2/2], Step [50/2], Loss: 0.5338\n",
            "Epoch [2/2], Step [60/2], Loss: 0.5996\n",
            "Epoch [2/2], Step [70/2], Loss: 0.5568\n",
            "Epoch [2/2], Step [80/2], Loss: 0.6185\n",
            "Epoch [2/2], Step [90/2], Loss: 0.6200\n",
            "Epoch [2/2], Step [100/2], Loss: 0.6588\n",
            "Epoch [2/2], Step [110/2], Loss: 0.8287\n",
            "Epoch [2/2], Step [120/2], Loss: 0.7042\n",
            "Epoch [2/2], Step [130/2], Loss: 0.6957\n",
            "Epoch [2/2], Step [140/2], Loss: 0.7800\n",
            "Epoch [2/2], Step [150/2], Loss: 0.5662\n",
            "Epoch [2/2], Step [160/2], Loss: 0.5279\n",
            "Epoch 1; loss = 0.6739\n",
            "0:00:10.695797\n",
            "0:00:20.902039\n"
          ]
        }
      ],
      "source": [
        "eye_epochs = []\n",
        "eye_losses = []\n",
        "timing = dict()\n",
        "timing['total_training'] = datetime.datetime.now()\n",
        "for epoch in range(num_epochs):\n",
        "    timing['training'] = datetime.datetime.now()\n",
        "    loss_total = 0.\n",
        "    iteration_count = 0.\n",
        "    for i, sample in enumerate(eye_train):\n",
        "        iteration_count += 1.\n",
        "        labels, marks = sample['label'], sample['marks'] \n",
        "        marks = marks.reshape(-1, sequence_length, input_size).to(device)\n",
        "        labels = labels.to(device)\n",
        "        if cuda_enabled:\n",
        "            marks = marks.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        # Forward + Backward + Optimize\n",
        "        eye_optimizer.zero_grad()\n",
        "        outputs = eye_model(marks)\n",
        "\n",
        "        loss = eye_criterion(outputs, labels)\n",
        "        loss_total += loss.item()\n",
        "        loss.backward()\n",
        "        eye_optimizer.step()\n",
        "\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                  % (epoch + 1, num_epochs, i + 1, len(eye_train) // batch_size, loss.item()))\n",
        "    current_epoch_loss = loss_total / iteration_count\n",
        "    print('Epoch %d; loss = %0.4f' % (epoch, current_epoch_loss))\n",
        "    eye_epochs.append(epoch)\n",
        "    eye_losses.append(current_epoch_loss)\n",
        "    timing['training'] = datetime.datetime.now() - timing['training']\n",
        "    print(timing['training'])\n",
        "    epoch_loss = current_epoch_loss\n",
        "\n",
        "timing['total_training'] = datetime.datetime.now() - timing['total_training']\n",
        "print(timing['total_training'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "bf079b7b-91e8-4acb-b30b-c1bff8f2f6dd",
      "metadata": {
        "id": "bf079b7b-91e8-4acb-b30b-c1bff8f2f6dd"
      },
      "outputs": [],
      "source": [
        "# Save the Model\n",
        "torch.save(eye_model.state_dict(), 'ShouldIDrive_eye_tracking_colab1_retesting.pkl')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "textfile = open(\"eyelosseslist.txt\", \"w\")\n",
        "for element in eye_losses:\n",
        "  textfile.write(str(element) + \"\\n\")\n",
        "textfile.close()\n",
        "\n",
        "plt.plot(eye_epochs, eye_losses)\n",
        "plt.title('Eye Tracking LSTM Training Loss',fontsize=15)\n",
        "plt.ylabel('Loss Rate',fontsize=12) \n",
        "plt.xlabel('Number of Epochs',fontsize=12) \n",
        "plt.grid(True) \n",
        "plt.savefig('eyelosscurve.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "0-COOPD2hcZv",
        "outputId": "3139b3ec-49db-4949-d658-fd5b6eda2562"
      },
      "id": "0-COOPD2hcZv",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you have previously trained the LSTM and have saved the model as a pickle file, then you can start loading the model here and testing :"
      ],
      "metadata": {
        "id": "H9tlSCZz0Fft"
      },
      "id": "H9tlSCZz0Fft"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Trained Eye Model"
      ],
      "metadata": {
        "id": "0PfCrx2-74hN"
      },
      "id": "0PfCrx2-74hN"
    },
    {
      "cell_type": "code",
      "source": [
        "eye_model_path = '/content/ShouldIDrive_eye_tracking_colab1_retesting.pkl'\n",
        "\n",
        "eye_model.load_state_dict(torch.load(eye_model_path))\n",
        "eye_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLXud0FnGtQE",
        "outputId": "f0f97b69-6d52-4b75-9724-88eb05322aa1"
      },
      "id": "GLXud0FnGtQE",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiRNN(\n",
              "  (lstm): LSTM(1, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
              "  (linear): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Eye LSTM"
      ],
      "metadata": {
        "id": "v91lB2X-jIXb"
      },
      "id": "v91lB2X-jIXb"
    },
    {
      "cell_type": "code",
      "source": [
        "eye_model.is_training = False\n",
        "timing = dict()\n",
        "timing['testing'] = datetime.datetime.now()\n",
        "print('Testing -----------------------------------------------')\n",
        "correct = 0.0\n",
        "for total, (sample) in enumerate(eye_test):\n",
        "      labels, marks = sample['label'], sample['marks']\n",
        "      marks = marks.reshape(-1, sequence_length, input_size).to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = eye_model(marks)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      if(predicted.__contains__(labels[0].item())): correct += 1.0\n",
        "\n",
        "total += 1\n",
        "print('Test Accuracy of {} model \\n on the {} test videos: {} %'.format(eye_model_path, total, 100 * correct / total)) \n",
        "timing['testing'] = datetime.datetime.now() - timing['testing']\n",
        "print(timing['testing'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVWbZipBiMa7",
        "outputId": "a4724573-9c48-495d-d28d-f5ec14a402f8"
      },
      "id": "YVWbZipBiMa7",
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing -----------------------------------------------\n",
            "Test Accuracy of /content/ShouldIDrive_eye_tracking_colab1_retesting.pkl model \n",
            " on the 69 test videos: 0.0 %\n",
            "0:00:02.712185\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Body LSTM"
      ],
      "metadata": {
        "id": "Z5uQbBA7jQiY"
      },
      "id": "Z5uQbBA7jQiY"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e092e79-02f4-4629-d2e7-473793758a7a",
        "id": "236NrfvqjYpQ"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/2], Step [10/2], Loss: 0.7324\n",
            "Epoch [1/2], Step [20/2], Loss: 0.7281\n",
            "Epoch [1/2], Step [30/2], Loss: 0.7151\n",
            "Epoch [1/2], Step [40/2], Loss: 0.6788\n",
            "Epoch [1/2], Step [50/2], Loss: 0.7016\n",
            "Epoch [1/2], Step [60/2], Loss: 0.6830\n",
            "Epoch [1/2], Step [70/2], Loss: 0.6968\n",
            "Epoch [1/2], Step [80/2], Loss: 0.6742\n",
            "Epoch [1/2], Step [90/2], Loss: 0.6839\n",
            "Epoch [1/2], Step [100/2], Loss: 0.6858\n",
            "Epoch [1/2], Step [110/2], Loss: 0.6706\n",
            "Epoch [1/2], Step [120/2], Loss: 0.7046\n",
            "Epoch [1/2], Step [130/2], Loss: 0.7495\n",
            "Epoch [1/2], Step [140/2], Loss: 0.6602\n",
            "Epoch [1/2], Step [150/2], Loss: 0.6340\n",
            "Epoch 0; loss = 0.6925\n",
            "0:00:13.881717\n",
            "Epoch [2/2], Step [10/2], Loss: 0.6535\n",
            "Epoch [2/2], Step [20/2], Loss: 0.6690\n",
            "Epoch [2/2], Step [30/2], Loss: 0.6424\n",
            "Epoch [2/2], Step [40/2], Loss: 0.7529\n",
            "Epoch [2/2], Step [50/2], Loss: 0.6350\n",
            "Epoch [2/2], Step [60/2], Loss: 0.6049\n",
            "Epoch [2/2], Step [70/2], Loss: 0.6370\n",
            "Epoch [2/2], Step [80/2], Loss: 0.6068\n",
            "Epoch [2/2], Step [90/2], Loss: 0.6280\n",
            "Epoch [2/2], Step [100/2], Loss: 0.6334\n",
            "Epoch [2/2], Step [110/2], Loss: 0.6198\n",
            "Epoch [2/2], Step [120/2], Loss: 0.7544\n",
            "Epoch [2/2], Step [130/2], Loss: 0.8090\n",
            "Epoch [2/2], Step [140/2], Loss: 0.6160\n",
            "Epoch [2/2], Step [150/2], Loss: 0.5895\n",
            "Epoch 1; loss = 0.6859\n",
            "0:00:13.611018\n",
            "0:00:27.493624\n"
          ]
        }
      ],
      "source": [
        "body_epochs = []\n",
        "body_losses = []\n",
        "timing = dict()\n",
        "timing['total_training'] = datetime.datetime.now()\n",
        "for epoch in range(num_epochs):\n",
        "    timing['training'] = datetime.datetime.now()\n",
        "    loss_total = 0.\n",
        "    iteration_count = 0.\n",
        "    for i, sample in enumerate(body_train):\n",
        "        iteration_count += 1.\n",
        "        labels, marks = sample['label'], sample['marks'] \n",
        "        marks = marks.reshape(-1, sequence_length, input_size).to(device)\n",
        "        labels = labels.to(device)\n",
        "        if cuda_enabled:\n",
        "            marks = marks.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        # Forward + Backward + Optimize\n",
        "        body_optimizer.zero_grad()\n",
        "        outputs = body_model(marks)\n",
        "\n",
        "        loss = body_criterion(outputs, labels)\n",
        "        loss_total += loss.item()\n",
        "        loss.backward()\n",
        "        body_optimizer.step()\n",
        "\n",
        "        if (i + 1) % 10 == 0:\n",
        "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                  % (epoch + 1, num_epochs, i + 1, len(body_train) // batch_size, loss.item()))\n",
        "    current_epoch_loss = loss_total / iteration_count\n",
        "    print('Epoch %d; loss = %0.4f' % (epoch, current_epoch_loss))\n",
        "    body_epochs.append(epoch)\n",
        "    body_losses.append(current_epoch_loss)\n",
        "    timing['training'] = datetime.datetime.now() - timing['training']\n",
        "    print(timing['training'])\n",
        "    epoch_loss = current_epoch_loss\n",
        "\n",
        "timing['total_training'] = datetime.datetime.now() - timing['total_training']\n",
        "print(timing['total_training'])\n"
      ],
      "id": "236NrfvqjYpQ"
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model\n",
        "torch.save(body_model.state_dict(), 'ShouldIDrive_body_tracking_colab1_retesting.pkl')"
      ],
      "metadata": {
        "id": "NqsC40G_j15Q"
      },
      "id": "NqsC40G_j15Q",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textfile = open(\"bodylosseslist.txt\", \"w\")\n",
        "for element in body_losses:\n",
        "  textfile.write(str(element) + \"\\n\")\n",
        "textfile.close()\n",
        "\n",
        "plt.plot(body_epochs, body_losses)\n",
        "plt.title('Body Tracking LSTM Training Loss',fontsize=15)\n",
        "plt.ylabel('Loss Rate',fontsize=12) \n",
        "plt.xlabel('Number of Epochs',fontsize=12) \n",
        "plt.grid(True) \n",
        "plt.savefig('bodylosscurve.png')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "-Oraiedej6NC",
        "outputId": "5157e2ac-1cf5-4da1-e98c-5fb4129d8d1a"
      },
      "id": "-Oraiedej6NC",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This next step can also work if you have access to an already saved trained model"
      ],
      "metadata": {
        "id": "3B94MwS8kE2d"
      },
      "id": "3B94MwS8kE2d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Trained Body Model"
      ],
      "metadata": {
        "id": "ikJZ275Y8JfC"
      },
      "id": "ikJZ275Y8JfC"
    },
    {
      "cell_type": "code",
      "source": [
        "body_model_path = '/content/ShouldIDrive_body_tracking_colab1_retesting.pkl'\n",
        "\n",
        "body_model.load_state_dict(torch.load(body_model_path))\n",
        "body_model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aak-YURHZp-W",
        "outputId": "2532a1da-75fe-499e-a9a6-ccb0a5f9b28e"
      },
      "id": "aak-YURHZp-W",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BiRNN(\n",
              "  (lstm): LSTM(1, 128, num_layers=2, batch_first=True, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=2, bias=True)\n",
              "  (linear): Linear(in_features=256, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Body LSTM"
      ],
      "metadata": {
        "id": "dVET3UsYkT0v"
      },
      "id": "dVET3UsYkT0v"
    },
    {
      "cell_type": "code",
      "source": [
        "body_model.is_training = False\n",
        "timing = dict()\n",
        "timing['testing'] = datetime.datetime.now()\n",
        "print('Testing -----------------------------------------------')\n",
        "correct = 0.0\n",
        "for total, (sample) in enumerate(body_test):\n",
        "      labels, marks = sample['label'], sample['marks']\n",
        "      marks = marks.reshape(-1, sequence_length, input_size).to(device)\n",
        "      labels = labels.to(device)\n",
        "      outputs = body_model(marks)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      if(predicted.__contains__(labels[0].item())): correct += 1.0\n",
        "\n",
        "total += 1\n",
        "print('Test Accuracy of {} model \\n on the {} test videos: {} %'.format(body_model_path, total, 100 * correct / total)) \n",
        "timing['testing'] = datetime.datetime.now() - timing['testing']\n",
        "print(timing['testing'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_ZwMrtDkTIV",
        "outputId": "fcdb292d-a112-4da5-931f-dba1e338445e"
      },
      "id": "3_ZwMrtDkTIV",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing -----------------------------------------------\n",
            "Test Accuracy of /content/ShouldIDrive_body_tracking_colab1_retesting.pkl model \n",
            " on the 66 test videos: 0.0 %\n",
            "0:00:03.968544\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Test the Model\n",
        "with torch.no_grad():\n",
        "  eye_model.is_training = False\n",
        "  timing = dict()\n",
        "  timing['testing'] = datetime.datetime.now()\n",
        "  print('Testing -----------------------------------------------')\n",
        "  correct = 0.0\n",
        "  total = 0.0\n",
        "  body_predicted_list = []\n",
        "  body_label_list = []\n",
        "  for i, sample in enumerate(eyedataset):#test_loader\n",
        "      \n",
        "      if(i ==228 ):\n",
        "        labels, marks = sample['label'], sample['marks'] \n",
        "        ogmarks = marks\n",
        "\n",
        "        marks = Variable(marks.view(-1, sequence_length, input_size))\n",
        "        labels = Variable(labels)\n",
        "        # if cuda_enabled:\n",
        "        #     marks = marks.cuda()\n",
        "        print(\"Labels\")\n",
        "        print(labels)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = eye_model(marks)\n",
        "        # print(outputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        print(\"Predicted labels\")\n",
        "        print(_)\n",
        "        p_tot = 0.0\n",
        "        for p, l in zip(_, labels):\n",
        "          p = p.item()\n",
        "          p_tot += p\n",
        "        accuracy = p_tot/len(labels)\n",
        "        print('Test Accuracy of the Eye Tracking model on the test video: \\n {:.4f} %'.format(100 * accuracy)) \n",
        "        break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySNvyD89xAp9",
        "outputId": "4055c807-33a7-4b54-d15b-f8e018e654ce"
      },
      "id": "ySNvyD89xAp9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing -----------------------------------------------\n",
            "Labels\n",
            "tensor([1, 1, 1, 1])\n",
            "Predicted labels\n",
            "tensor([0.4248, 0.1220, 0.1220, 0.1220])\n",
            "Test Accuracy of the Eye Tracking model on the test video: \n",
            " 19.7705 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eye_model.load_state_dict(torch.load(eye_model_path, map_location=torch.device('cpu')))\n",
        "# print(eye_model.eval())\n",
        "\n",
        "correct = 0.0\n",
        "predicted_list = []\n",
        "label_list = []\n",
        "print('Testing -----------------------------------------------')\n",
        "\n",
        "for total, (sample) in enumerate(eyedataset):\n",
        "        # if(total==100):\n",
        "        #   break\n",
        "        if(total ==228 ):\n",
        "          labels, marks = sample['label'], sample['marks']\n",
        "          marks = marks.reshape(-1, sequence_length, input_size).to(device)\n",
        "          labels = labels.to(device)\n",
        "          print(\"Labels\")\n",
        "          print(labels)\n",
        "          outputs = eye_model(marks)\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          # print(labels[0][0].item())\n",
        "          print(\"Predicted labels\")\n",
        "          print(predicted)\n",
        "          for p, l in zip(predicted, labels):\n",
        "            predicted_list.append(p.item())\n",
        "            label_list.append(l.item())  \n",
        "\n",
        "          accuracy = accuracy_score(label_list, predicted_list)\n",
        "\n",
        "          print('Test Accuracy of the Eye Tracking model on the test video: \\n {:.4f} %'.format(100 * accuracy)) \n",
        "          break\n",
        "      # break\n",
        "\n",
        "# print('Test Accuracy of {} model \\n on the {} test videos: {} %'.format(eye_model_path, total, 100 * correct / total)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "yyur999kJzt_",
        "outputId": "43f3b894-2ea3-4895-bcb0-ae4aab49d365"
      },
      "id": "yyur999kJzt_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9bf3d1e7811b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0meye_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meye_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(eye_model.eval())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredicted_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'eye_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "977accd2-1554-42d1-be09-dbc1c4768f29",
      "metadata": {
        "id": "977accd2-1554-42d1-be09-dbc1c4768f29",
        "outputId": "eb0395f7-5a90-44bf-a62a-40e94ba8d352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-958fc66b4285>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# # Test the Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0meye_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtiming\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'testing'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Testing -----------------------------------------------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'eye_model' is not defined"
          ]
        }
      ],
      "source": [
        "# # Test the Model\n",
        "eye_model.is_training = False\n",
        "timing = dict()\n",
        "timing['testing'] = datetime.datetime.now()\n",
        "print('Testing -----------------------------------------------')\n",
        "correct = 0.0\n",
        "total = 0.0\n",
        "eye_predicted_list = []\n",
        "eye_label_list = []\n",
        "auc = []\n",
        "with torch.no_grad():\n",
        "  for i, sample in enumerate(eye_test):#test_loader\n",
        "      labels, marks = sample['label'], sample['marks'] \n",
        "      marks = marks.reshape(-1, sequence_length, input_size).to(device)\n",
        "      # labels = labels.to(device)\n",
        "      if cuda_enabled:\n",
        "          marks = marks.cuda()\n",
        "\n",
        "      outputs = eye_model(marks)\n",
        "      outputs = torch.sigmoid(outputs)\n",
        "      # print(outputs)\n",
        "      y_pred_tag = torch.round(outputs)\n",
        "      # print(y_pred_tag)\n",
        "      print(labels[0])\n",
        "      print(marks[0])\n",
        "      eye_predicted_list.append(y_pred_tag.cpu().numpy())\n",
        "\n",
        "    # outputs = F.log_softmax(eye_model.linear(outputs), dim=1)\n",
        "    # _, pred = outputs.data.cpu().topk(1, dim=1)\n",
        "    # # _, predicted = torch.max(outputs.data, 1)\n",
        "    # # _, predicted = outputs.data\n",
        "    # predicted = predicted.t()\n",
        "    # y_pred = eye_model(marks)\n",
        "    # # print(y_pred)\n",
        "    # # print(labels)\n",
        "    # accuracy=binary_acc(y_pred,labels).item()\n",
        "    # test_acc = torch.sum(y_pred == labels)\n",
        "    # print(accuracy)\n",
        "    # auc.append(accuracy)\n",
        "\n",
        "    # print(_)\n",
        "    # print(predicted)\n",
        "    # total += labels.size(0)\n",
        "    # for p, l in zip(_, labels):\n",
        "    #     # eye_p = int(np.round(p).item())\n",
        "    #     # eye_l = l[0].item()\n",
        "        \n",
        "    #     eye_predicted_list.append(eye_p)\n",
        "    #     eye_label_list.append(eye_l)\n",
        "    #     if(eye_p == eye_l):\n",
        "            # print(eye_p)\n",
        "            # print(eye_l)\n",
        "            # if(p.item()>0.95):\n",
        "            #     print(p.item())\n",
        "            #     print(eye_l)\n",
        "            # print(sample['marks'][0][:5])\n",
        "            # correct += 1.0\n",
        "    # print(correct)\n",
        "    # auc.append(100 * correct / total)\n",
        "\n",
        "# print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total)) \n",
        "eye_predicted_list = [a.squeeze().tolist() for a in eye_predicted_list]\n",
        "print(eye_predicted_list)\n",
        "# print(classification_report(label_list, eye_predicted_list))\n",
        "# print('Accuracy = %0.4f' % (accuracy_score(label_list, eye_predicted_list)))\n",
        "timing['testing'] = datetime.datetime.now() - timing['testing']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de13f12b-0345-4ca6-a7cd-1c06095d883d",
      "metadata": {
        "id": "de13f12b-0345-4ca6-a7cd-1c06095d883d"
      },
      "outputs": [],
      "source": [
        "# # Test the Model\n",
        "model.is_training = False\n",
        "timing['testing'] = datetime.datetime.now()\n",
        "print('Testing -----------------------------------------------')\n",
        "correct = 0.0\n",
        "total = 0.0\n",
        "predicted_list = []\n",
        "label_list = []\n",
        "for mfcc, labels in test_loader:#test_loader\n",
        "    mfcc = Variable(mfcc.view(-1, sequence_length, input_size))\n",
        "    if cuda_enabled:\n",
        "        mfcc = mfcc.cuda()\n",
        "\n",
        "    outputs = rnn(mfcc)\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    for p, l in zip(predicted, labels):\n",
        "        predicted_list.append(p)\n",
        "        label_list.append(l)\n",
        "        if p == l:\n",
        "            correct += 1.0\n",
        "\n",
        "timing['testing'] = datetime.datetime.now() - timing['testing']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cef17084-4f99-4756-a8d3-3692c37270c2",
      "metadata": {
        "id": "cef17084-4f99-4756-a8d3-3692c37270c2",
        "outputId": "a6e840a5-5d94-4074-b59c-328fc584bb7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 97.39 %\n"
          ]
        }
      ],
      "source": [
        "# Test the model\n",
        "# with torch.no_grad():\n",
        "#     model.is_training = False\n",
        "#     correct = 0\n",
        "#     total = 0\n",
        "#     for images, labels in test_loader:\n",
        "#         images = images.reshape(-1, sequence_length, input_size).to(device)\n",
        "#         labels = labels.to(device)\n",
        "#         outputs = model(images)\n",
        "#         _, predicted = torch.max(outputs.data, 1)\n",
        "#         total += labels.size(0)\n",
        "#         correct += (predicted == labels).sum().item()\n",
        "\n",
        "#     print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total)) "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "LSTMEyeandBody.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}