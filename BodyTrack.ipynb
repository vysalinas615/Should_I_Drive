{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59741880-564d-4f9a-970b-d0d44980d7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in ./.local/cori/3.9-anaconda-2021.11/lib/python3.9/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing-extensions in /global/common/software/nersc/cori-2022q1/sw/python/3.9-anaconda-2021.11/lib/python3.9/site-packages (from torch) (3.10.0.2)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "!{sys.executable} -m pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05f44c8b-8642-42dd-b894-461819d8bddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torchvision in ./.local/cori/3.9-anaconda-2021.11/lib/python3.9/site-packages (0.12.0)\n",
      "Requirement already satisfied: typing-extensions in /global/common/software/nersc/cori-2022q1/sw/python/3.9-anaconda-2021.11/lib/python3.9/site-packages (from torchvision) (3.10.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /global/common/software/nersc/cori-2022q1/sw/python/3.9-anaconda-2021.11/lib/python3.9/site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: numpy in /global/common/software/nersc/cori-2022q1/sw/python/3.9-anaconda-2021.11/lib/python3.9/site-packages (from torchvision) (1.20.3)\n",
      "Requirement already satisfied: requests in /global/common/software/nersc/cori-2022q1/sw/python/3.9-anaconda-2021.11/lib/python3.9/site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: torch==1.11.0 in ./.local/cori/3.9-anaconda-2021.11/lib/python3.9/site-packages (from torchvision) (1.11.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /global/common/software/nersc/cori-2022q1/sw/python/3.9-anaconda-2021.11/lib/python3.9/site-packages (from requests->torchvision) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /global/common/software/nersc/cori-2022q1/sw/python/3.9-anaconda-2021.11/lib/python3.9/site-packages (from requests->torchvision) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /global/common/software/nersc/cori-2022q1/sw/python/3.9-anaconda-2021.11/lib/python3.9/site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /global/common/software/nersc/cori-2022q1/sw/python/3.9-anaconda-2021.11/lib/python3.9/site-packages (from requests->torchvision) (2021.10.8)\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "!{sys.executable} -m pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b8b32c8-43b9-4c26-99ec-e93cd593857d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x1554c47a5dc0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torch.backends.cudnn as cudnn\n",
    "cuda_enabled = torch.cuda.is_available()\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#cuda_enabled = False\n",
    "CUDA_VISIBLE_DEVICES=0,1,2,3\n",
    "cudnn.benchmark = True\n",
    "\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from __future__ import print_function, division\n",
    "import datetime\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1440638-1ece-4c7e-9fd5-3065b80b4f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiRNN, self).__init__()\n",
    "        self.is_training = False\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = num_classes\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Dropout(p=0.5, inplace=False)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "        self.linear = nn.Linear(self.hidden_size*2, self.num_classes)\n",
    "        if cuda_enabled:\n",
    "            self.lstm = self.lstm.cuda()\n",
    "            self.fc = self.fc.cuda()\n",
    "            self.linear = self.linear.cuda()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Set initial states\n",
    "        h0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size)) # 2 for bidirection \n",
    "        c0 = Variable(torch.zeros(self.num_layers*2, x.size(0), self.hidden_size))\n",
    "        if cuda_enabled:\n",
    "            h0 = h0.cuda()  # 2 for bidirection\n",
    "            c0 = c0.cuda()\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
    "        \n",
    "        # Decode hidden state of last time step\n",
    "        if self.is_training:\n",
    "            out = self.fc(out[:, -1, :])\n",
    "        else:\n",
    "            out = out[:, -1, :]\n",
    "        # out = F.log_softmax(self.linear(out), dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b31d8558-9bb1-4a28-a072-42f0158de099",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BodyLandmarksDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, transform=None):#root_dir = img_dir\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)#same as image label\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        name = self.landmarks_frame.iloc[idx, 0]\n",
    "        labels = np.zeros(36)\n",
    "        for i in range(4):\n",
    "            labels[i]=name\n",
    "        labels = torch.Tensor(labels).long()\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 1:]\n",
    "        marks = []\n",
    "        for mark in range(len(landmarks)):\n",
    "            arr=literal_eval(landmarks[mark])\n",
    "            arr = np.array(arr)\n",
    "            marks.append(arr)                         \n",
    "        marks = torch.Tensor(marks)\n",
    "        \n",
    "        sample = {'label': labels, 'marks': marks}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "475097c1-1302-4ea2-84f5-0f606627020b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, torch.Size([36]), torch.Size([181, 36]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bodydataset = BodyLandmarksDataset(csv_file='CSVs/BodyTracking.csv')\n",
    "bodydataset.__len__(), bodydataset.__getitem__(0)['label'].shape, bodydataset.__getitem__(0)['marks'].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f84eadfc-6b34-4dbf-b9f0-6e75d248cc47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Body NN dataset -------------------------------------\n",
      "224 <__main__.BodyLandmarksDataset object at 0x1554c8094130>\n",
      "156 <torch.utils.data.dataset.Subset object at 0x1555505541f0>\n",
      "68 <torch.utils.data.dataset.Subset object at 0x155550554ac0>\n",
      "Starting Body NN loader -------------------------------------\n",
      "3 <torch.utils.data.dataloader.DataLoader object at 0x1554c1dfd220>\n",
      "2 <torch.utils.data.dataloader.DataLoader object at 0x1554c1dfde50>\n",
      "Finish  -------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def train_total_dataset(dataset, total_split=0.30): #Training set be 70% of the dataset\n",
    "    train_idx, total_idx = train_test_split(list(range(len(dataset))), test_size=total_split)\n",
    "    datasets = {}\n",
    "    datasets['train'] = Subset(dataset, train_idx)\n",
    "    datasets['total_split'] = Subset(dataset, total_idx)\n",
    "    return datasets\n",
    "\n",
    "# hyperparams for the network\n",
    "batch_size = 64\n",
    "\n",
    "print('Starting Body NN dataset -------------------------------------')\n",
    "body_datasets = train_total_dataset(bodydataset)\n",
    "body_train = body_datasets['train']\n",
    "body_test = body_datasets['total_split']\n",
    "# The original dataset is available in the Subset class\n",
    "print(len(body_datasets['train'].dataset), body_datasets['train'].dataset)\n",
    "print(len(body_train), body_train)\n",
    "print(len(body_test), body_test)\n",
    "\n",
    "print('Starting Body NN loader -------------------------------------')\n",
    "body_train_loader = DataLoader(dataset=body_train, batch_size=batch_size, shuffle=True)\n",
    "body_test_loader = DataLoader(dataset=body_test, batch_size=batch_size, shuffle=False)\n",
    "print(len(body_train_loader), body_train_loader)\n",
    "print(len(body_test_loader), body_test_loader)\n",
    "print('Finish  -------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e5d704e-5c73-4363-9f04-82b1308dec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-08 13:32:11.604728\n"
     ]
    }
   ],
   "source": [
    "#Init NN\n",
    "timing = dict()\n",
    "timing['training'] = datetime.datetime.now()\n",
    "print(timing['training'])\n",
    "input_size = 1\n",
    "sequence_length = 181\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "num_classes = 2  # TODO: Determine this from the data\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 300\n",
    "\n",
    "# The network\n",
    "body_model = BiRNN(input_size, hidden_size, num_layers, num_classes)\n",
    "body_model.is_training = True\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(body_model.parameters(), lr=learning_rate)\n",
    "\n",
    "epoch_loss = 5000000000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d632214-eac1-4d21-a6cb-17a1a2e3e7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/300], Step [10/2], Loss: 0.6820\n",
      "Epoch [1/300], Step [20/2], Loss: 0.6708\n",
      "Epoch [1/300], Step [30/2], Loss: 0.4819\n",
      "Epoch [1/300], Step [40/2], Loss: 0.4465\n",
      "Epoch [1/300], Step [50/2], Loss: 0.6215\n",
      "Epoch [1/300], Step [60/2], Loss: 0.4637\n",
      "Epoch [1/300], Step [70/2], Loss: 0.2739\n",
      "Epoch [1/300], Step [80/2], Loss: 0.3399\n",
      "Epoch [1/300], Step [90/2], Loss: 0.3862\n",
      "Epoch [1/300], Step [100/2], Loss: 0.0442\n",
      "Epoch [1/300], Step [110/2], Loss: 0.0385\n",
      "Epoch [1/300], Step [120/2], Loss: 0.0378\n",
      "Epoch [1/300], Step [130/2], Loss: 0.0397\n",
      "Epoch [1/300], Step [140/2], Loss: 0.3981\n",
      "Epoch [1/300], Step [150/2], Loss: 0.3660\n",
      "Epoch 0; loss = 0.3609\n",
      "Epoch [2/300], Step [10/2], Loss: 0.3306\n",
      "Epoch [2/300], Step [20/2], Loss: 0.3808\n",
      "Epoch [2/300], Step [30/2], Loss: 0.0833\n",
      "Epoch [2/300], Step [40/2], Loss: 0.0831\n",
      "Epoch [2/300], Step [50/2], Loss: 0.3397\n",
      "Epoch [2/300], Step [60/2], Loss: 0.3179\n",
      "Epoch [2/300], Step [70/2], Loss: 0.0358\n",
      "Epoch [2/300], Step [80/2], Loss: 0.3926\n",
      "Epoch [2/300], Step [90/2], Loss: 0.3398\n",
      "Epoch [2/300], Step [100/2], Loss: 0.0359\n",
      "Epoch [2/300], Step [110/2], Loss: 0.0676\n",
      "Epoch [2/300], Step [120/2], Loss: 0.0455\n",
      "Epoch [2/300], Step [130/2], Loss: 0.0414\n",
      "Epoch [2/300], Step [140/2], Loss: 0.4130\n",
      "Epoch [2/300], Step [150/2], Loss: 0.3664\n",
      "Epoch 1; loss = 0.2010\n",
      "Epoch [3/300], Step [10/2], Loss: 0.2992\n",
      "Epoch [3/300], Step [20/2], Loss: 0.3666\n",
      "Epoch [3/300], Step [30/2], Loss: 0.0914\n",
      "Epoch [3/300], Step [40/2], Loss: 0.0822\n",
      "Epoch [3/300], Step [50/2], Loss: 0.3449\n",
      "Epoch [3/300], Step [60/2], Loss: 0.3196\n",
      "Epoch [3/300], Step [70/2], Loss: 0.0356\n",
      "Epoch [3/300], Step [80/2], Loss: 0.3930\n",
      "Epoch [3/300], Step [90/2], Loss: 0.3229\n",
      "Epoch [3/300], Step [100/2], Loss: 0.0383\n",
      "Epoch [3/300], Step [110/2], Loss: 0.0618\n",
      "Epoch [3/300], Step [120/2], Loss: 0.0431\n",
      "Epoch [3/300], Step [130/2], Loss: 0.0434\n",
      "Epoch [3/300], Step [140/2], Loss: 0.4064\n",
      "Epoch [3/300], Step [150/2], Loss: 0.3595\n",
      "Epoch 2; loss = 0.1955\n",
      "Epoch [4/300], Step [10/2], Loss: 0.2686\n",
      "Epoch [4/300], Step [20/2], Loss: 0.3526\n",
      "Epoch [4/300], Step [30/2], Loss: 0.0968\n",
      "Epoch [4/300], Step [40/2], Loss: 0.0790\n",
      "Epoch [4/300], Step [50/2], Loss: 0.3436\n",
      "Epoch [4/300], Step [60/2], Loss: 0.3334\n",
      "Epoch [4/300], Step [70/2], Loss: 0.0378\n",
      "Epoch [4/300], Step [80/2], Loss: 0.3937\n",
      "Epoch [4/300], Step [90/2], Loss: 0.2990\n",
      "Epoch [4/300], Step [100/2], Loss: 0.0405\n",
      "Epoch [4/300], Step [110/2], Loss: 0.0542\n",
      "Epoch [4/300], Step [120/2], Loss: 0.0425\n",
      "Epoch [4/300], Step [130/2], Loss: 0.0497\n",
      "Epoch [4/300], Step [140/2], Loss: 0.3993\n",
      "Epoch [4/300], Step [150/2], Loss: 0.3455\n",
      "Epoch 3; loss = 0.1902\n",
      "Epoch [5/300], Step [10/2], Loss: 0.2361\n",
      "Epoch [5/300], Step [20/2], Loss: 0.3436\n",
      "Epoch [5/300], Step [30/2], Loss: 0.1009\n",
      "Epoch [5/300], Step [40/2], Loss: 0.0727\n",
      "Epoch [5/300], Step [50/2], Loss: 0.3416\n",
      "Epoch [5/300], Step [60/2], Loss: 0.3455\n",
      "Epoch [5/300], Step [70/2], Loss: 0.0377\n",
      "Epoch [5/300], Step [80/2], Loss: 0.3992\n",
      "Epoch [5/300], Step [90/2], Loss: 0.2801\n",
      "Epoch [5/300], Step [100/2], Loss: 0.0420\n",
      "Epoch [5/300], Step [110/2], Loss: 0.0502\n",
      "Epoch [5/300], Step [120/2], Loss: 0.0400\n",
      "Epoch [5/300], Step [130/2], Loss: 0.0546\n",
      "Epoch [5/300], Step [140/2], Loss: 0.3983\n",
      "Epoch [5/300], Step [150/2], Loss: 0.3276\n",
      "Epoch 4; loss = 0.1855\n",
      "Epoch [6/300], Step [10/2], Loss: 0.2124\n",
      "Epoch [6/300], Step [20/2], Loss: 0.3371\n",
      "Epoch [6/300], Step [30/2], Loss: 0.1039\n",
      "Epoch [6/300], Step [40/2], Loss: 0.0656\n",
      "Epoch [6/300], Step [50/2], Loss: 0.3330\n",
      "Epoch [6/300], Step [60/2], Loss: 0.3414\n",
      "Epoch [6/300], Step [70/2], Loss: 0.0350\n",
      "Epoch [6/300], Step [80/2], Loss: 0.4032\n",
      "Epoch [6/300], Step [90/2], Loss: 0.2653\n",
      "Epoch [6/300], Step [100/2], Loss: 0.0437\n",
      "Epoch [6/300], Step [110/2], Loss: 0.0455\n",
      "Epoch [6/300], Step [120/2], Loss: 0.0356\n",
      "Epoch [6/300], Step [130/2], Loss: 0.0598\n",
      "Epoch [6/300], Step [140/2], Loss: 0.4008\n",
      "Epoch [6/300], Step [150/2], Loss: 0.3297\n",
      "Epoch 5; loss = 0.1799\n",
      "Epoch [7/300], Step [10/2], Loss: 0.1886\n",
      "Epoch [7/300], Step [20/2], Loss: 0.3284\n",
      "Epoch [7/300], Step [30/2], Loss: 0.1038\n",
      "Epoch [7/300], Step [40/2], Loss: 0.0607\n",
      "Epoch [7/300], Step [50/2], Loss: 0.3223\n",
      "Epoch [7/300], Step [60/2], Loss: 0.3232\n",
      "Epoch [7/300], Step [70/2], Loss: 0.0343\n",
      "Epoch [7/300], Step [80/2], Loss: 0.3941\n",
      "Epoch [7/300], Step [90/2], Loss: 0.2559\n",
      "Epoch [7/300], Step [100/2], Loss: 0.0473\n",
      "Epoch [7/300], Step [110/2], Loss: 0.0374\n",
      "Epoch [7/300], Step [120/2], Loss: 0.0321\n",
      "Epoch [7/300], Step [130/2], Loss: 0.0655\n",
      "Epoch [7/300], Step [140/2], Loss: 0.4030\n",
      "Epoch [7/300], Step [150/2], Loss: 0.3423\n",
      "Epoch 6; loss = 0.1735\n",
      "Epoch [8/300], Step [10/2], Loss: 0.1647\n",
      "Epoch [8/300], Step [20/2], Loss: 0.3193\n",
      "Epoch [8/300], Step [30/2], Loss: 0.1023\n",
      "Epoch [8/300], Step [40/2], Loss: 0.0570\n",
      "Epoch [8/300], Step [50/2], Loss: 0.3093\n",
      "Epoch [8/300], Step [60/2], Loss: 0.3072\n",
      "Epoch [8/300], Step [70/2], Loss: 0.0353\n",
      "Epoch [8/300], Step [80/2], Loss: 0.3801\n",
      "Epoch [8/300], Step [90/2], Loss: 0.2473\n",
      "Epoch [8/300], Step [100/2], Loss: 0.0504\n",
      "Epoch [8/300], Step [110/2], Loss: 0.0301\n",
      "Epoch [8/300], Step [120/2], Loss: 0.0300\n",
      "Epoch [8/300], Step [130/2], Loss: 0.0749\n",
      "Epoch [8/300], Step [140/2], Loss: 0.4030\n",
      "Epoch [8/300], Step [150/2], Loss: 0.3462\n",
      "Epoch 7; loss = 0.1675\n",
      "Epoch [9/300], Step [10/2], Loss: 0.1459\n",
      "Epoch [9/300], Step [20/2], Loss: 0.3125\n",
      "Epoch [9/300], Step [30/2], Loss: 0.1018\n",
      "Epoch [9/300], Step [40/2], Loss: 0.0548\n",
      "Epoch [9/300], Step [50/2], Loss: 0.2969\n",
      "Epoch [9/300], Step [60/2], Loss: 0.3050\n",
      "Epoch [9/300], Step [70/2], Loss: 0.0349\n",
      "Epoch [9/300], Step [80/2], Loss: 0.3784\n",
      "Epoch [9/300], Step [90/2], Loss: 0.2332\n",
      "Epoch [9/300], Step [100/2], Loss: 0.0529\n",
      "Epoch [9/300], Step [110/2], Loss: 0.0266\n",
      "Epoch [9/300], Step [120/2], Loss: 0.0300\n",
      "Epoch [9/300], Step [130/2], Loss: 0.0810\n",
      "Epoch [9/300], Step [140/2], Loss: 0.3993\n",
      "Epoch [9/300], Step [150/2], Loss: 0.3411\n",
      "Epoch 8; loss = 0.1633\n",
      "Epoch [10/300], Step [10/2], Loss: 0.1299\n",
      "Epoch [10/300], Step [20/2], Loss: 0.3092\n",
      "Epoch [10/300], Step [30/2], Loss: 0.1028\n",
      "Epoch [10/300], Step [40/2], Loss: 0.0532\n",
      "Epoch [10/300], Step [50/2], Loss: 0.2859\n",
      "Epoch [10/300], Step [60/2], Loss: 0.3073\n",
      "Epoch [10/300], Step [70/2], Loss: 0.0353\n",
      "Epoch [10/300], Step [80/2], Loss: 0.3713\n",
      "Epoch [10/300], Step [90/2], Loss: 0.2216\n",
      "Epoch [10/300], Step [100/2], Loss: 0.0550\n",
      "Epoch [10/300], Step [110/2], Loss: 0.0247\n",
      "Epoch [10/300], Step [120/2], Loss: 0.0305\n",
      "Epoch [10/300], Step [130/2], Loss: 0.0840\n",
      "Epoch [10/300], Step [140/2], Loss: 0.3992\n",
      "Epoch [10/300], Step [150/2], Loss: 0.3336\n",
      "Epoch 9; loss = 0.1602\n",
      "Epoch [11/300], Step [10/2], Loss: 0.1177\n",
      "Epoch [11/300], Step [20/2], Loss: 0.3073\n",
      "Epoch [11/300], Step [30/2], Loss: 0.1021\n",
      "Epoch [11/300], Step [40/2], Loss: 0.0512\n",
      "Epoch [11/300], Step [50/2], Loss: 0.2754\n",
      "Epoch [11/300], Step [60/2], Loss: 0.3064\n",
      "Epoch [11/300], Step [70/2], Loss: 0.0350\n",
      "Epoch [11/300], Step [80/2], Loss: 0.3707\n",
      "Epoch [11/300], Step [90/2], Loss: 0.2110\n",
      "Epoch [11/300], Step [100/2], Loss: 0.0544\n",
      "Epoch [11/300], Step [110/2], Loss: 0.0212\n",
      "Epoch [11/300], Step [120/2], Loss: 0.0296\n",
      "Epoch [11/300], Step [130/2], Loss: 0.0880\n",
      "Epoch [11/300], Step [140/2], Loss: 0.3981\n",
      "Epoch [11/300], Step [150/2], Loss: 0.3283\n",
      "Epoch 10; loss = 0.1578\n",
      "Epoch [12/300], Step [10/2], Loss: 0.1084\n",
      "Epoch [12/300], Step [20/2], Loss: 0.3059\n",
      "Epoch [12/300], Step [30/2], Loss: 0.0993\n",
      "Epoch [12/300], Step [40/2], Loss: 0.0494\n",
      "Epoch [12/300], Step [50/2], Loss: 0.2606\n",
      "Epoch [12/300], Step [60/2], Loss: 0.2902\n",
      "Epoch [12/300], Step [70/2], Loss: 0.0349\n",
      "Epoch [12/300], Step [80/2], Loss: 0.3729\n",
      "Epoch [12/300], Step [90/2], Loss: 0.2047\n",
      "Epoch [12/300], Step [100/2], Loss: 0.0527\n",
      "Epoch [12/300], Step [110/2], Loss: 0.0178\n",
      "Epoch [12/300], Step [120/2], Loss: 0.0278\n",
      "Epoch [12/300], Step [130/2], Loss: 0.0904\n",
      "Epoch [12/300], Step [140/2], Loss: 0.3961\n",
      "Epoch [12/300], Step [150/2], Loss: 0.3235\n",
      "Epoch 11; loss = 0.1557\n",
      "Epoch [13/300], Step [10/2], Loss: 0.1038\n",
      "Epoch [13/300], Step [20/2], Loss: 0.3052\n",
      "Epoch [13/300], Step [30/2], Loss: 0.0986\n",
      "Epoch [13/300], Step [40/2], Loss: 0.0476\n",
      "Epoch [13/300], Step [50/2], Loss: 0.2471\n",
      "Epoch [13/300], Step [60/2], Loss: 0.2728\n",
      "Epoch [13/300], Step [70/2], Loss: 0.0362\n",
      "Epoch [13/300], Step [80/2], Loss: 0.3686\n",
      "Epoch [13/300], Step [90/2], Loss: 0.1932\n",
      "Epoch [13/300], Step [100/2], Loss: 0.0521\n",
      "Epoch [13/300], Step [110/2], Loss: 0.0168\n",
      "Epoch [13/300], Step [120/2], Loss: 0.0268\n",
      "Epoch [13/300], Step [130/2], Loss: 0.0902\n",
      "Epoch [13/300], Step [140/2], Loss: 0.3965\n",
      "Epoch [13/300], Step [150/2], Loss: 0.3181\n",
      "Epoch 12; loss = 0.1542\n",
      "Epoch [14/300], Step [10/2], Loss: 0.1021\n",
      "Epoch [14/300], Step [20/2], Loss: 0.3049\n",
      "Epoch [14/300], Step [30/2], Loss: 0.0930\n",
      "Epoch [14/300], Step [40/2], Loss: 0.0458\n",
      "Epoch [14/300], Step [50/2], Loss: 0.2315\n",
      "Epoch [14/300], Step [60/2], Loss: 0.2582\n",
      "Epoch [14/300], Step [70/2], Loss: 0.0362\n",
      "Epoch [14/300], Step [80/2], Loss: 0.3671\n",
      "Epoch [14/300], Step [90/2], Loss: 0.1804\n",
      "Epoch [14/300], Step [100/2], Loss: 0.0515\n",
      "Epoch [14/300], Step [110/2], Loss: 0.0157\n",
      "Epoch [14/300], Step [120/2], Loss: 0.0260\n",
      "Epoch [14/300], Step [130/2], Loss: 0.0916\n",
      "Epoch [14/300], Step [140/2], Loss: 0.3970\n",
      "Epoch [14/300], Step [150/2], Loss: 0.3143\n",
      "Epoch 13; loss = 0.1524\n",
      "Epoch [15/300], Step [10/2], Loss: 0.0994\n",
      "Epoch [15/300], Step [20/2], Loss: 0.3048\n",
      "Epoch [15/300], Step [30/2], Loss: 0.0920\n",
      "Epoch [15/300], Step [40/2], Loss: 0.0447\n",
      "Epoch [15/300], Step [50/2], Loss: 0.2206\n",
      "Epoch [15/300], Step [60/2], Loss: 0.2484\n",
      "Epoch [15/300], Step [70/2], Loss: 0.0368\n",
      "Epoch [15/300], Step [80/2], Loss: 0.3611\n",
      "Epoch [15/300], Step [90/2], Loss: 0.1718\n",
      "Epoch [15/300], Step [100/2], Loss: 0.0511\n",
      "Epoch [15/300], Step [110/2], Loss: 0.0156\n",
      "Epoch [15/300], Step [120/2], Loss: 0.0255\n",
      "Epoch [15/300], Step [130/2], Loss: 0.0926\n",
      "Epoch [15/300], Step [140/2], Loss: 0.3972\n",
      "Epoch [15/300], Step [150/2], Loss: 0.3110\n",
      "Epoch 14; loss = 0.1512\n",
      "Epoch [16/300], Step [10/2], Loss: 0.0983\n",
      "Epoch [16/300], Step [20/2], Loss: 0.3050\n",
      "Epoch [16/300], Step [30/2], Loss: 0.0899\n",
      "Epoch [16/300], Step [40/2], Loss: 0.0435\n"
     ]
    }
   ],
   "source": [
    "epochs = []\n",
    "losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    loss_total = 0.\n",
    "    iteration_count = 0.\n",
    "    for i, sample in enumerate(body_train):\n",
    "        iteration_count += 1.\n",
    "        labels, marks = sample['label'], sample['marks'] \n",
    "        marks = Variable(marks.view(-1, sequence_length, input_size))\n",
    "        labels = Variable(labels)\n",
    "        if cuda_enabled:\n",
    "            marks = marks.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "        # Forward + Backward + Optimize\n",
    "        optimizer.zero_grad()\n",
    "        outputs = body_model(marks)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss_total += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                  % (epoch + 1, num_epochs, i + 1, len(body_train) // batch_size, loss.item()))\n",
    "    current_epoch_loss = loss_total / iteration_count\n",
    "    print('Epoch %d; loss = %0.4f' % (epoch, current_epoch_loss))\n",
    "    epochs.append(epoch)\n",
    "    losses.append(current_epoch_loss)\n",
    "    epoch_loss = current_epoch_loss\n",
    "timing['training'] = datetime.datetime.now() - timing['training']\n",
    "print(timing['training'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5c92c8-f93a-467b-9763-359e2d6b4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(body_model.state_dict(), 'ShouldIDrive_body_tracking.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ca92e1-c077-4226-8dea-5435febca8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epochs, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b8017-300d-42b2-ac3b-cf34a2360d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_model.is_training = False\n",
    "timing['testing'] = datetime.datetime.now()\n",
    "print('Testing -----------------------------------------------')\n",
    "correct = 0.0\n",
    "total = 0.0\n",
    "body_predicted_list = []\n",
    "body_label_list = []\n",
    "for i, sample in enumerate(body_test_loader):#test_loader\n",
    "    labels, marks = sample['label'], sample['marks'] \n",
    "    marks = Variable(marks.view(-1, sequence_length, input_size))\n",
    "    if cuda_enabled:\n",
    "        marks = marks.cuda()\n",
    "\n",
    "    outputs = body_model(marks)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    # print(total)\n",
    "    for p, l in zip(_, labels):\n",
    "        body_p = int(np.round(p).item())\n",
    "        body_l = l[0].item()\n",
    "        body_predicted_list.append(body_p)\n",
    "        body_label_list.append(body_l)\n",
    "        if(body_p == body_l):\n",
    "            correct += 1.0\n",
    "    print(correct)\n",
    "print('Test Accuracy of the model on the {} test images: {} %'.format(total, 100 * correct / total)) \n",
    "\n",
    "timing['testing'] = datetime.datetime.now() - timing['testing']\n",
    "print(timing['testing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443bf899-2935-4274-b5a8-5b6ff9aeeb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion Matrix')\n",
    "print('================')\n",
    "print(confusion_matrix(body_label_list, body_predicted_list))\n",
    "print('=============================================')\n",
    "print('Accuracy = %0.4f' % (accuracy_score(body_label_list, body_predicted_list)))\n",
    "print('=============================================')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NERSC Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
